{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'IBM'\n",
    "start_day = '1999-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ozing\\miniconda3\\envs\\RL_trader\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ticker = yf.Ticker(symbol)\n",
    "IBM_history = ticker.history(start=start_day)\n",
    "\n",
    "IBM_history.drop(['Dividends', 'Stock Splits'], axis=1, inplace=True)\n",
    "\n",
    "IBM_history['Prev_close'] = IBM_history['Close'].shift()\n",
    "IBM_history['Rate'] = (IBM_history['Close'] - IBM_history['Prev_close']) / IBM_history['Prev_close'] * 100\n",
    "IBM_history['Rate'][0] = (IBM_history['Close'][0] - IBM_history['Open'][0]) / IBM_history['Open'][0] * 100\n",
    "IBM_history['Rate'] = IBM_history['Rate'].round(decimals=2)\n",
    "\n",
    "IBM_history.reset_index(inplace=True)\n",
    "IBM_history['Date'] = IBM_history['Date'].dt.strftime('%Y-%m-%d')\n",
    "IBM_history.set_index(IBM_history['Date'], inplace=True)\n",
    "IBM_history.drop(['Date', 'Prev_close'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "data_rolling = IBM_history['Close'].rolling(window_size, min_periods=1)\n",
    "IBM_history[f'MA_{window_size}'] = data_rolling.mean().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ozing\\miniconda3\\envs\\RL_trader\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\Users\\ozing\\miniconda3\\envs\\RL_trader\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "IBM_history['Upper Band'] = IBM_history[f'MA_{window_size}'] + (2 * data_rolling.std())\n",
    "IBM_history['Lower Band'] = IBM_history[f'MA_{window_size}'] - (2 * data_rolling.std())\n",
    "IBM_history['Upper Band'][0] = IBM_history[f'MA_{window_size}'][0] + (2 * np.std([IBM_history['Open'][0], IBM_history['Close'][0]]))\n",
    "IBM_history['Lower Band'][0] = IBM_history[f'MA_{window_size}'][0] - (2 * np.std([IBM_history['Open'][0], IBM_history['Close'][0]]))\n",
    "\n",
    "IBM_history['Upper Band'] = IBM_history['Upper Band'].round(2)\n",
    "IBM_history['Lower Band'] = IBM_history['Lower Band'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = yf.Ticker('^GSPC')\n",
    "sp500_history = sp500.history(start=start_day)\n",
    "\n",
    "sp500_history.reset_index(inplace=True)\n",
    "sp500_history['Date'] = sp500_history['Date'].dt.strftime('%Y-%m-%d')\n",
    "sp500_history.set_index(sp500_history['Date'], inplace=True)\n",
    "sp500_history.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "sp500_history.rename({'Close':'SP500'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = yf.Ticker('^IXIC')\n",
    "nasdaq_history = nasdaq.history(start=start_day)\n",
    "\n",
    "nasdaq_history.reset_index(inplace=True)\n",
    "nasdaq_history['Date'] = nasdaq_history['Date'].dt.strftime('%Y-%m-%d')\n",
    "nasdaq_history.set_index(nasdaq_history['Date'], inplace=True)\n",
    "nasdaq_history.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "nasdaq_history.rename({'Close':'Nasdaq'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([IBM_history, sp500_history['SP500'].round(2), nasdaq_history['Nasdaq'].round(2)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Rate</th>\n",
       "      <th>MA_20</th>\n",
       "      <th>Upper Band</th>\n",
       "      <th>Lower Band</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Nasdaq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-04</th>\n",
       "      <td>50.220337</td>\n",
       "      <td>50.627530</td>\n",
       "      <td>49.270221</td>\n",
       "      <td>49.677414</td>\n",
       "      <td>8524482</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>49</td>\n",
       "      <td>49.54</td>\n",
       "      <td>48.46</td>\n",
       "      <td>1228.10</td>\n",
       "      <td>2208.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-05</th>\n",
       "      <td>49.677430</td>\n",
       "      <td>51.543728</td>\n",
       "      <td>49.626534</td>\n",
       "      <td>51.475861</td>\n",
       "      <td>10363350</td>\n",
       "      <td>3.62</td>\n",
       "      <td>50</td>\n",
       "      <td>52.54</td>\n",
       "      <td>47.46</td>\n",
       "      <td>1244.78</td>\n",
       "      <td>2251.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-06</th>\n",
       "      <td>51.662494</td>\n",
       "      <td>52.324182</td>\n",
       "      <td>51.170471</td>\n",
       "      <td>51.238335</td>\n",
       "      <td>9978422</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>50</td>\n",
       "      <td>51.95</td>\n",
       "      <td>48.05</td>\n",
       "      <td>1272.34</td>\n",
       "      <td>2320.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-07</th>\n",
       "      <td>51.017772</td>\n",
       "      <td>52.222383</td>\n",
       "      <td>50.763278</td>\n",
       "      <td>51.628559</td>\n",
       "      <td>8688913</td>\n",
       "      <td>0.76</td>\n",
       "      <td>51</td>\n",
       "      <td>52.80</td>\n",
       "      <td>49.20</td>\n",
       "      <td>1269.73</td>\n",
       "      <td>2326.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-08</th>\n",
       "      <td>51.849127</td>\n",
       "      <td>52.120588</td>\n",
       "      <td>50.390021</td>\n",
       "      <td>50.915977</td>\n",
       "      <td>9598933</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>50</td>\n",
       "      <td>51.56</td>\n",
       "      <td>48.44</td>\n",
       "      <td>1275.09</td>\n",
       "      <td>2344.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03</th>\n",
       "      <td>134.695514</td>\n",
       "      <td>135.288224</td>\n",
       "      <td>133.885456</td>\n",
       "      <td>135.278351</td>\n",
       "      <td>3754500</td>\n",
       "      <td>0.40</td>\n",
       "      <td>138</td>\n",
       "      <td>146.28</td>\n",
       "      <td>129.72</td>\n",
       "      <td>4136.48</td>\n",
       "      <td>12006.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-06</th>\n",
       "      <td>134.181829</td>\n",
       "      <td>134.665888</td>\n",
       "      <td>133.312502</td>\n",
       "      <td>134.527573</td>\n",
       "      <td>4841300</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>138</td>\n",
       "      <td>146.32</td>\n",
       "      <td>129.68</td>\n",
       "      <td>4111.08</td>\n",
       "      <td>11887.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>134.023761</td>\n",
       "      <td>134.744899</td>\n",
       "      <td>132.818563</td>\n",
       "      <td>134.191696</td>\n",
       "      <td>3737600</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>137</td>\n",
       "      <td>145.35</td>\n",
       "      <td>128.65</td>\n",
       "      <td>4164.00</td>\n",
       "      <td>12113.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>134.063289</td>\n",
       "      <td>135.080790</td>\n",
       "      <td>133.519960</td>\n",
       "      <td>134.330002</td>\n",
       "      <td>4593700</td>\n",
       "      <td>0.10</td>\n",
       "      <td>137</td>\n",
       "      <td>145.13</td>\n",
       "      <td>128.87</td>\n",
       "      <td>4117.86</td>\n",
       "      <td>11910.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>134.990005</td>\n",
       "      <td>135.729996</td>\n",
       "      <td>133.339996</td>\n",
       "      <td>133.750000</td>\n",
       "      <td>3917400</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>136</td>\n",
       "      <td>143.77</td>\n",
       "      <td>128.23</td>\n",
       "      <td>4081.50</td>\n",
       "      <td>11789.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6066 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume  Rate  MA_20  Upper Band  Lower Band    SP500    Nasdaq\n",
       "Date                                                                                                                        \n",
       "1999-01-04   50.220337   50.627530   49.270221   49.677414   8524482 -1.08     49       49.54       48.46  1228.10   2208.05\n",
       "1999-01-05   49.677430   51.543728   49.626534   51.475861  10363350  3.62     50       52.54       47.46  1244.78   2251.27\n",
       "1999-01-06   51.662494   52.324182   51.170471   51.238335   9978422 -0.46     50       51.95       48.05  1272.34   2320.86\n",
       "1999-01-07   51.017772   52.222383   50.763278   51.628559   8688913  0.76     51       52.80       49.20  1269.73   2326.09\n",
       "1999-01-08   51.849127   52.120588   50.390021   50.915977   9598933 -1.38     50       51.56       48.44  1275.09   2344.41\n",
       "...                ...         ...         ...         ...       ...   ...    ...         ...         ...      ...       ...\n",
       "2023-02-03  134.695514  135.288224  133.885456  135.278351   3754500  0.40    138      146.28      129.72  4136.48  12006.95\n",
       "2023-02-06  134.181829  134.665888  133.312502  134.527573   4841300 -0.55    138      146.32      129.68  4111.08  11887.45\n",
       "2023-02-07  134.023761  134.744899  132.818563  134.191696   3737600 -0.25    137      145.35      128.65  4164.00  12113.79\n",
       "2023-02-08  134.063289  135.080790  133.519960  134.330002   4593700  0.10    137      145.13      128.87  4117.86  11910.52\n",
       "2023-02-09  134.990005  135.729996  133.339996  133.750000   3917400 -0.43    136      143.77      128.23  4081.50  11789.58\n",
       "\n",
       "[6066 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = data[:int(len(data)*0.8)]\n",
    "# test_data = data[int(len(data)*0.8):]\n",
    "\n",
    "# time_len = 128\n",
    "# X_train, y_train = [], []\n",
    "# for i in range(time_len, len(train_data)):\n",
    "#   X_train.append(train_data[i-time_len:i]) # Chunks of training data with a length of 128 df-rows\n",
    "#   y_train.append(train_data['Close'][i]) #Value of 4th column (Close Price) of df-row 128+1\n",
    "# X_train, y_train = np.array(X_train, dtype=np.float32), np.array(y_train, dtype=np.float32)\n",
    "\n",
    "# X_test, y_test = [], []\n",
    "# for i in range(time_len, len(test_data)):\n",
    "#   X_test.append(test_data[i-time_len:i]) # Chunks of training data with a length of 128 df-rows\n",
    "#   y_test.append(test_data['Close'][i]) #Value of 4th column (Close Price) of df-row 128+1\n",
    "# X_test, y_test = np.array(X_test, dtype=np.float32), np.array(y_test, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import LSTM, Input, Dense, Dropout\n",
    "# from keras.models import Sequential\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# model = Sequential([\n",
    "#     Input(shape=(time_len, len(data.columns))),\n",
    "#     LSTM(256, return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(64),\n",
    "#     Dense(1),\n",
    "# ])\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mape'])\n",
    "\n",
    "# es = EarlyStopping(monitor='mape', patience=2)\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=64, epochs=30, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(14,5))\n",
    "# plt.plot(y_test, label='True')\n",
    "# plt.plot(model.predict(X_test, verbose=0), label='Pred')\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Input, Dense, Lambda, Subtract, Add, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def smape_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    sMAPE loss as defined in \"Appendix A\" of\n",
    "    http://www.forecastingprinciples.com/files/pdf/Makridakia-The%20M3%20Competition.pdf\n",
    "    :return: Loss value\n",
    "    \"\"\"\n",
    "    # mask=tf.where(y_true,1.,0.)\n",
    "    mask = tf.cast(y_true, tf.bool)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    sym_sum = tf.abs(y_true) + tf.abs(y_pred)\n",
    "    condition = tf.cast(sym_sum, tf.bool)\n",
    "    weights = tf.where(condition, 1. / (sym_sum + 1e-8), 0.0)\n",
    "    return tf.convert_to_tensor(200 * np.nanmean(tf.abs(y_pred - y_true) * weights * mask))\n",
    "    # return np.mean((np.abs(y_true-y_pred))/(np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "\n",
    "class NBeatsNet:\n",
    "    GENERIC_BLOCK = 'generic'\n",
    "    TREND_BLOCK = 'trend'\n",
    "    SEASONALITY_BLOCK = 'seasonality'\n",
    "\n",
    "    _BACKCAST = 'backcast'\n",
    "    _FORECAST = 'forecast'\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim=1,\n",
    "                 output_dim=1,\n",
    "                 exo_dim=0,\n",
    "                 backcast_length=10,\n",
    "                 forecast_length=1,\n",
    "                 stack_types=(TREND_BLOCK, SEASONALITY_BLOCK),\n",
    "                 nb_blocks_per_stack=3,\n",
    "                 thetas_dim=(4, 8),\n",
    "                 share_weights_in_stack=False,\n",
    "                 hidden_layer_units=256,\n",
    "                 nb_harmonics=None):\n",
    "\n",
    "        self.stack_types = stack_types\n",
    "        self.nb_blocks_per_stack = nb_blocks_per_stack\n",
    "        self.thetas_dim = thetas_dim\n",
    "        self.units = hidden_layer_units\n",
    "        self.share_weights_in_stack = share_weights_in_stack\n",
    "        self.backcast_length = backcast_length\n",
    "        self.forecast_length = forecast_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.exo_dim = exo_dim\n",
    "        self.input_shape = (self.backcast_length, self.input_dim)\n",
    "        self.exo_shape = (self.backcast_length, self.exo_dim)\n",
    "        self.output_shape = (self.forecast_length, self.output_dim)\n",
    "        self.weights = {}\n",
    "        self.nb_harmonics = nb_harmonics\n",
    "        self._gen_intermediate_outputs = False\n",
    "        self._intermediary_outputs = []\n",
    "        assert len(self.stack_types) == len(self.thetas_dim)\n",
    "\n",
    "        x = Input(shape=self.input_shape, name='input_variable')\n",
    "        x_ = {}\n",
    "        for k in range(self.input_dim):\n",
    "            x_[k] = Lambda(lambda z: z[..., k])(x)\n",
    "        e_ = {}\n",
    "        if self.has_exog():\n",
    "            e = Input(shape=self.exo_shape, name='exos_variables')\n",
    "            for k in range(self.exo_dim):\n",
    "                e_[k] = Lambda(lambda z: z[..., k])(e)\n",
    "        else:\n",
    "            e = None\n",
    "        y_ = {}\n",
    "\n",
    "        for stack_id in range(len(self.stack_types)):\n",
    "            stack_type = self.stack_types[stack_id]\n",
    "            nb_poly = self.thetas_dim[stack_id]\n",
    "            for block_id in range(self.nb_blocks_per_stack):\n",
    "                backcast, forecast = self.create_block(x_, e_, stack_id, block_id, stack_type, nb_poly)\n",
    "                for k in range(self.input_dim):\n",
    "                    x_[k] = Subtract()([x_[k], backcast[k]])\n",
    "                    layer_name = f'stack_{stack_id}-{stack_type.title()}Block_{block_id}'\n",
    "                    if self.input_dim >= 1:\n",
    "                        layer_name += f'_Dim_{k}'\n",
    "                    # rename.\n",
    "                    forecast[k] = Lambda(function=lambda _x: _x, name=layer_name)(forecast[k])\n",
    "                    if stack_id == 0 and block_id == 0:\n",
    "                        y_[k] = forecast[k]\n",
    "                    else:\n",
    "                        y_[k] = Add()([y_[k], forecast[k]])\n",
    "\n",
    "        for k in range(self.input_dim):\n",
    "            y_[k] = Reshape(target_shape=(self.forecast_length, 1))(y_[k])\n",
    "            x_[k] = Reshape(target_shape=(self.backcast_length, 1))(x_[k])\n",
    "        if self.input_dim > 1:\n",
    "            y_ = Concatenate()([y_[ll] for ll in range(self.input_dim)])\n",
    "            x_ = Concatenate()([x_[ll] for ll in range(self.input_dim)])\n",
    "        else:\n",
    "            y_ = y_[0]\n",
    "            x_ = x_[0]\n",
    "\n",
    "        if self.input_dim != self.output_dim:\n",
    "            y_ = Dense(self.output_dim, activation='linear', name='reg_y')(y_)\n",
    "            x_ = Dense(self.output_dim, activation='linear', name='reg_x')(x_)\n",
    "\n",
    "        inputs_x = [x, e] if self.has_exog() else x\n",
    "        n_beats_forecast = Model(inputs_x, y_, name=self._FORECAST)\n",
    "        n_beats_backcast = Model(inputs_x, x_, name=self._BACKCAST)\n",
    "\n",
    "        self.models = {model.name: model for model in [n_beats_backcast, n_beats_forecast]}\n",
    "        self.cast_type = self._FORECAST\n",
    "\n",
    "    def get_generic_and_interpretable_outputs(self):\n",
    "        g_pred = sum([a['value'][0] for a in self._intermediary_outputs if 'generic' in a['layer'].lower()])\n",
    "        i_pred = sum([a['value'][0] for a in self._intermediary_outputs if 'generic' not in a['layer'].lower()])\n",
    "        outputs = {o['layer']: o['value'][0] for o in self._intermediary_outputs}\n",
    "        return g_pred, i_pred, outputs\n",
    "\n",
    "    def has_exog(self):\n",
    "        # exo/exog is short for 'exogenous variable', i.e. any input\n",
    "        # features other than the target time-series itself.\n",
    "        return self.exo_dim > 0\n",
    "\n",
    "    @staticmethod\n",
    "    def name():\n",
    "        return 'NBeatsKeras'\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filepath, custom_objects=None, compile=True):\n",
    "        from keras.models import load_model\n",
    "        return load_model(filepath, custom_objects, compile)\n",
    "\n",
    "    def _r(self, layer_with_weights, stack_id):\n",
    "        # mechanism to restore weights when block share the same weights.\n",
    "        # only useful when share_weights_in_stack=True.\n",
    "        if self.share_weights_in_stack:\n",
    "            layer_name = layer_with_weights.name.split('/')[-1]\n",
    "            try:\n",
    "                reused_weights = self.weights[stack_id][layer_name]\n",
    "                return reused_weights\n",
    "            except KeyError:\n",
    "                pass\n",
    "            if stack_id not in self.weights:\n",
    "                self.weights[stack_id] = {}\n",
    "            self.weights[stack_id][layer_name] = layer_with_weights\n",
    "        return layer_with_weights\n",
    "\n",
    "    def disable_intermediate_outputs(self):\n",
    "        self._gen_intermediate_outputs = False\n",
    "\n",
    "    def enable_intermediate_outputs(self):\n",
    "        self._gen_intermediate_outputs = True\n",
    "\n",
    "    def create_block(self, x, e, stack_id, block_id, stack_type, nb_poly):\n",
    "        # register weights (useful when share_weights_in_stack=True)\n",
    "        def reg(layer):\n",
    "            return self._r(layer, stack_id)\n",
    "\n",
    "        # update name (useful when share_weights_in_stack=True)\n",
    "        def n(layer_name):\n",
    "            return '/'.join([str(stack_id), str(block_id), stack_type, layer_name])\n",
    "\n",
    "        backcast_ = {}\n",
    "        forecast_ = {}\n",
    "        d1 = reg(Dense(self.units, activation='relu', name=n('d1')))\n",
    "        d2 = reg(Dense(self.units, activation='relu', name=n('d2')))\n",
    "        d3 = reg(Dense(self.units, activation='relu', name=n('d3')))\n",
    "        d4 = reg(Dense(self.units, activation='relu', name=n('d4')))\n",
    "        if stack_type == 'generic':\n",
    "            theta_b = reg(Dense(nb_poly, activation='linear', use_bias=False, name=n('theta_b')))\n",
    "            theta_f = reg(Dense(nb_poly, activation='linear', use_bias=False, name=n('theta_f')))\n",
    "            backcast = reg(Dense(self.backcast_length, activation='linear', name=n('backcast')))\n",
    "            forecast = reg(Dense(self.forecast_length, activation='linear', name=n('forecast')))\n",
    "        elif stack_type == 'trend':\n",
    "            theta_f = theta_b = reg(Dense(nb_poly, activation='linear', use_bias=False, name=n('theta_f_b')))\n",
    "            backcast = Lambda(trend_model, arguments={'is_forecast': False, 'backcast_length': self.backcast_length,\n",
    "                                                      'forecast_length': self.forecast_length})\n",
    "            forecast = Lambda(trend_model, arguments={'is_forecast': True, 'backcast_length': self.backcast_length,\n",
    "                                                      'forecast_length': self.forecast_length})\n",
    "        else:  # 'seasonality'\n",
    "            if self.nb_harmonics:\n",
    "                theta_b = reg(Dense(self.nb_harmonics, activation='linear', use_bias=False, name=n('theta_b')))\n",
    "            else:\n",
    "                theta_b = reg(Dense(self.forecast_length, activation='linear', use_bias=False, name=n('theta_b')))\n",
    "            theta_f = reg(Dense(self.forecast_length, activation='linear', use_bias=False, name=n('theta_f')))\n",
    "            backcast = Lambda(seasonality_model,\n",
    "                              arguments={'is_forecast': False, 'backcast_length': self.backcast_length,\n",
    "                                         'forecast_length': self.forecast_length})\n",
    "            forecast = Lambda(seasonality_model,\n",
    "                              arguments={'is_forecast': True, 'backcast_length': self.backcast_length,\n",
    "                                         'forecast_length': self.forecast_length})\n",
    "        for k in range(self.input_dim):\n",
    "            if self.has_exog():\n",
    "                d0 = Concatenate()([x[k]] + [e[ll] for ll in range(self.exo_dim)])\n",
    "            else:\n",
    "                d0 = x[k]\n",
    "            d1_ = d1(d0)\n",
    "            d2_ = d2(d1_)\n",
    "            d3_ = d3(d2_)\n",
    "            d4_ = d4(d3_)\n",
    "            theta_f_ = theta_f(d4_)\n",
    "            theta_b_ = theta_b(d4_)\n",
    "            backcast_[k] = backcast(theta_b_)\n",
    "            forecast_[k] = forecast(theta_f_)\n",
    "\n",
    "        return backcast_, forecast_\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        # https://github.com/faif/python-patterns\n",
    "        # model.predict() instead of model.n_beats.predict()\n",
    "        # same for fit(), train_on_batch()...\n",
    "        attr = getattr(self.models[self._FORECAST], name)\n",
    "\n",
    "        if not callable(attr):\n",
    "            return attr\n",
    "\n",
    "        def wrapper(*args, **kwargs):\n",
    "            cast_type = self._FORECAST\n",
    "            if attr.__name__ == 'predict' and 'return_backcast' in kwargs and kwargs['return_backcast']:\n",
    "                del kwargs['return_backcast']\n",
    "                cast_type = self._BACKCAST\n",
    "\n",
    "            if attr.__name__ == 'predict' and self._gen_intermediate_outputs:\n",
    "                import keract\n",
    "                outputs = keract.get_activations(model=self, x=args)\n",
    "                self._intermediary_outputs = [\n",
    "                    {'layer': a, 'value': b} for a, b in outputs.items() if str(a).startswith('stack_')\n",
    "                ]\n",
    "            return getattr(self.models[cast_type], attr.__name__)(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "\n",
    "def linear_space(backcast_length, forecast_length, is_forecast=True):\n",
    "    # ls = K.arange(-float(backcast_length), float(forecast_length), 1) / forecast_length\n",
    "    # return ls[backcast_length:] if is_forecast else K.abs(K.reverse(ls[:backcast_length], axes=0))\n",
    "    horizon = forecast_length if is_forecast else backcast_length\n",
    "    return K.arange(0, horizon) / horizon\n",
    "\n",
    "\n",
    "def seasonality_model(thetas, backcast_length, forecast_length, is_forecast):\n",
    "    p = thetas.get_shape().as_list()[-1]\n",
    "    p1, p2 = (p // 2, p // 2) if p % 2 == 0 else (p // 2, p // 2 + 1)\n",
    "    t = linear_space(backcast_length, forecast_length, is_forecast=is_forecast)\n",
    "    s1 = K.stack([K.cos(2 * np.pi * i * t) for i in range(p1)])\n",
    "    s2 = K.stack([K.sin(2 * np.pi * i * t) for i in range(p2)])\n",
    "    if p == 1:\n",
    "        s = s2\n",
    "    else:\n",
    "        s = K.concatenate([s1, s2], axis=0)\n",
    "    s = K.cast(s, np.float32)\n",
    "    return K.dot(thetas, s)\n",
    "\n",
    "\n",
    "def trend_model(thetas, backcast_length, forecast_length, is_forecast):\n",
    "    p = thetas.shape[-1]\n",
    "    t = linear_space(backcast_length, forecast_length, is_forecast=is_forecast)\n",
    "    t = K.transpose(K.stack([t ** i for i in range(p)]))\n",
    "    t = K.cast(t, np.float32)\n",
    "    return K.dot(thetas, K.transpose(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "150/150 [==============================] - 32s 116ms/step - loss: 1089.2333 - mape: 1435.2488\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 17s 117ms/step - loss: 245.7637 - mape: 327.1858\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 18s 118ms/step - loss: 134.3179 - mape: 175.8299\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 18s 118ms/step - loss: 113.4006 - mape: 148.5361\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 18s 118ms/step - loss: 69.7521 - mape: 91.2676\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 18s 117ms/step - loss: 46.7946 - mape: 60.5139\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 17s 116ms/step - loss: 28.2341 - mape: 35.5053\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 17s 117ms/step - loss: 24.2621 - mape: 29.6955\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 18s 119ms/step - loss: 20.4223 - mape: 24.2672\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 17s 116ms/step - loss: 19.7083 - mape: 23.1016\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 18s 118ms/step - loss: 18.9531 - mape: 22.1033\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 18s 118ms/step - loss: 19.4948 - mape: 22.7120\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 17s 115ms/step - loss: 18.4291 - mape: 21.2345\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 18s 120ms/step - loss: 18.7995 - mape: 21.7463\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 17s 116ms/step - loss: 18.7481 - mape: 21.6495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c53f768608>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "num_rows = len(data)\n",
    "num_columns = len(data.columns)\n",
    "forecast_length = 20\n",
    "backcast_length = 3 * forecast_length\n",
    "\n",
    "train_data = data[:int(len(data)*0.8)]\n",
    "test_data = data[int(len(data)*0.8):]\n",
    "\n",
    "X_train, y_train = [], []\n",
    "for i in range(backcast_length, len(train_data)-forecast_length):\n",
    "  X_train.append(train_data[i-backcast_length:i]) # Chunks of training data with a length of 128 df-rows\n",
    "  y_train.append(train_data['Close'][i:i+forecast_length]) #Value of 4th column (Close Price) of df-row 128+1\n",
    "X_train, y_train = np.array(X_train, dtype=np.float32), np.array(y_train, dtype=np.float32)\n",
    "\n",
    "X_test, y_test = [], []\n",
    "for i in range(backcast_length, len(test_data)-forecast_length):\n",
    "  X_test.append(test_data[i-backcast_length:i]) # Chunks of training data with a length of 128 df-rows\n",
    "  y_test.append(test_data['Close'][i:i+forecast_length]) #Value of 4th column (Close Price) of df-row 128+1\n",
    "X_test, y_test = np.array(X_test, dtype=np.float32), np.array(y_test, dtype=np.float32)\n",
    "\n",
    "# noinspection PyArgumentEqualDefault\n",
    "model = NBeatsNet(\n",
    "    input_dim=num_columns,\n",
    "    output_dim=1,\n",
    "    forecast_length=forecast_length,\n",
    "    backcast_length=backcast_length,\n",
    ")\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mape'])\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=30, callbacks=[es])\n",
    "\n",
    "# num_predictions = len(X_test)\n",
    "# predictions = model.predict(X_test)\n",
    "# np.testing.assert_equal(predictions.shape, (num_predictions, 1, 1))\n",
    "# data['P'] = [np.nan] * (num_rows - num_predictions) + list(model.predict(X_test).squeeze(axis=(1, 2)))\n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 2s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_test[0], label='TRUE')\n",
    "plt.plot(pred, label='PRED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_trader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1b95a97914c6dc21ec8e571aafa166e58bf71eab4b4b6e194898531688be29a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
